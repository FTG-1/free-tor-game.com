<!doctype html><html lang="en-US"><!--  --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- / -->
<head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1">  <link media="all" href="https://free-tor-game.com/wp-content/cache/autoptimize/4/css/autoptimize_dc56928889f08ceb40a4520f8ece953b.css" rel="stylesheet" /><title>Architecture &#8211; Saving high-frequency events to a connection-limit constrained database &#8211; free-tor-game.com</title> <script>MathJax = {
  tex: {
    inlineMath: [['$','$'],['\\(','\\)']], 
    processEscapes: true
  },
  options: {
    ignoreHtmlClass: 'tex2jax_ignore|editor-rich-text'
  }
};</script> <link rel='dns-prefetch' href='http://cdn.jsdelivr.net/' /><link rel='dns-prefetch' href='http://cdnjs.cloudflare.com/' /><link rel='dns-prefetch' href='http://stackpath.bootstrapcdn.com/' /><link rel='dns-prefetch' href='http://s.w.org/' /><link rel='stylesheet' id='highlight-css'  href='https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.2.0/styles/vs2015.min.css?ver=5.6' type='text/css' media='all' /><link rel='stylesheet' id='bootstrap-css'  href='https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css?ver=4.1.3' type='text/css' media='all' /><link rel='stylesheet' id='icons-css'  href='https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css?ver=5.6' type='text/css' media='all' /> <script type='text/javascript' src='https://cdnjs.cloudflare.com/ajax/libs/jquery/1.12.4/jquery.min.js?ver=1.12.4' id='jquery-js'></script> <script type='text/javascript' src='https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.2.0/highlight.min.js?ver=11.2.0' id='highlight-js'></script>     <script>( function( w, d, s, l, i ) {
				w[l] = w[l] || [];
				w[l].push( {'gtm.start': new Date().getTime(), event: 'gtm.js'} );
				var f = d.getElementsByTagName( s )[0],
					j = d.createElement( s ), dl = l != 'dataLayer' ? '&l=' + l : '';
				j.async = true;
				j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
				f.parentNode.insertBefore( j, f );
			} )( window, document, 'script', 'dataLayer', ' ' );</script>      <script>hljs.highlightAll();</script> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-1731162805004860" crossorigin="anonymous"></script></head><body class="software-template-default single single-software postid-1085275 no-sidebar"><div id="page" class="site"> <a class="skip-link screen-reader-text" href="#content">Skip to content</a><header id="topnav" class="sticky-top"><nav class="navbar navbar-expand-md navbar-light bg-light" role="navigation"> <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-primary" aria-controls="navbar-primary" aria-expanded="false" aria-label="Toggle navigation"> <span class="navbar-toggler-icon"></span> </button> <a class="navbar-brand" href="#">free-tor-game.com</a><div id="navbar-primary" class="collapse navbar-collapse"><ul id="menu-primary-top-menu" class="nav navbar-nav"><li itemscope="itemscope" itemtype="https://www.schema.org/SiteNavigationElement" id="menu-item-192" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children dropdown menu-item-192 nav-item"><a title="Tools" href="#" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false" class="dropdown-toggle nav-link" id="menu-item-dropdown-192">Tools</a><ul class="dropdown-menu" aria-labelledby="menu-item-dropdown-192" role="menu"><li itemscope="itemscope" itemtype="https://www.schema.org/SiteNavigationElement" id="menu-item-193" class="menu-item menu-item-type-post_type menu-item-object-post menu-item-193 nav-item"><a title="ARFCN-Frequency Converter" href="https://free-tor-game.com/3gpp-arfcn-frequency-converter/" class="dropdown-item">ARFCN-Frequency Converter</a></li></ul></li><li itemscope="itemscope" itemtype="https://www.schema.org/SiteNavigationElement" id="menu-item-2301" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2301 nav-item"><a title="Contact Us" href="https://free-tor-game.com/contact/" class="nav-link">Contact Us</a></li></ul></div></nav></header><div id="content" class="site-content"><div id="primary" class="content-area"><main id="main" class="site-main"><div id="main-container" class="container"><div id="main-row" class="row"><div id="main-col" class="col-12"><article id="post-1085275" class="post-1085275 software type-software status-publish hentry category-software tag-architecture tag-event-sourcing tag-performance tag-scalability"><div class="row"><div class="col-12 col-md-8"><header class="entry-header"><h1 class="entry-title text-danger">Architecture &#8211; Saving high-frequency events to a connection-limit constrained database</h1></header><p style='font-size:1.2em'><span class="mr-2 badge badge-success">Architecture</span><span class="mr-2 badge badge-info">event-sourcing</span><span class="mr-2 badge badge-warning">performance</span><span class="mr-2 badge badge-primary">scalability</span></p><div class="entry-content"><p>We&#39;ve got a situation where I have to deal with a massive influx of events coming in to our server, at about 1000 events per second, on average (peak could be ~2000).</p><h2>The problem</h2><p>Our system is hosted on <a href="https://www.heroku.com/" rel="noreferrer">Heroku</a> and uses a relatively expensive <a href="https://www.heroku.com/postgres" rel="noreferrer">Heroku Postgres DB</a>, that allows a maximum of 500 DB connections. We use connection pooling to connect from the server to the DB.</p><h3>Events come in faster than the DB connection pool can handle</h3><p>The problem we have is that events come faster than the connection pool can handle. By the time one connection has finished the network roundtrip from the server to the DB, so it can get released back to the pool, more than <code>n</code> additional events come in.</p><p>Eventually the events stack up, waiting to get saved and because there are no available connections in the pool, they time out and the whole system is rendered non-operational.</p><p>We&#39;ve solved the emergency by emitting the offending high-frequency events at a slower pace from the clients, but we still want to know how to handle this scenarios in the event we need to handle that high-frequency events.</p><h2>Constraints</h2><h3>Other clients might want to read events concurrently</h3><p>Other clients continuously request to read all the events with a particular key, even if they are not saved in the DB yet.</p><p>A client can query <code>GET api/v1/events?clientId=1</code> and get all the events sent by client 1, even if those events are not done saving in the DB just yet.</p><p>Are there any &#34;classroom&#34; examples on how to deal with this?</p><h2>Possible solutions</h2><h3>Enqueue the events on our server</h3><p>We could enqueue the events on the server (with the queue having a maximum concurrency of 400 so the connection pool doesn&#39;t run out).</p><p>This is <em>bad idea</em> because:</p><ul><li>It will eat up available server memory. The stacked-up enqueued events will consume massive amounts of RAM.</li><li>Our servers <strong>restart once every 24 hours</strong>. This is a <a href="https://devcenter.heroku.com/articles/dynos#restarting" rel="noreferrer">hard limit</a> imposed by Heroku. The server can restart while events are enqueued causing us to lose the enqueued events.</li><li>It introduces state on the server, thus hurting scalability. If we have a multi-server setup and a client wants to read all the enqueued + saved events, we won&#39;t know on which server the enqueued events live.</li></ul><h3>Use a separate message queue</h3><p>I assume we could use a message queue, (like <a href="https://www.rabbitmq.com/" rel="noreferrer">RabbitMQ</a>?), where we pump the messages in it and on the other end there is another server that only deals with saving the events on the DB.</p><p>I&#39;m not sure if message queues allow querying enqueued events (that weren&#39;t saved yet) so if another client wants to read the messages of another client, I can just get the saved messages from the DB and the pending messages from the queue and concatenate them together so I can send them back to the read-request client.</p><h3>Use multiple databases, each saving a portion of the messages with a central DB-coordinator server to manage them</h3><p>Another solution we&#39;ve though is to use multiple databases, with a central &#34;DB coordinator/load balancer&#34;. Upon receiving an event it<br /> this coordinator would choose one of the databases to write the message to. This should allow us to use multiple Heroku databases thus upping the connection limit to 500 x number of databases.</p><p>Upon a read query, this coordinator could issue <code>SELECT</code> queries to each database, merge all the results and send them back to the client that requested the read.</p><p>This is <em>bad idea</em> because:</p><ul><li>This idea sounds like &#8230; ahem.. over-engineering? Would be a nightmare to manage as well (backups etc..). It&#39;s complicated to build and maintain and unless it&#39;s absolutely necessary it sounds like a <a href="https://en.wikipedia.org/wiki/KISS_principle" rel="noreferrer">KISS</a> violation.</li><li>It sacrifices <em>Consistency</em>. Doing transactions across multiple DB&#39;s is a no-go if we go with this idea.</li></ul></div>     <div id="comments" class="comments-area"><div class="row"><div class="col-12"><div class="mt-3 border-bottom border-success"><h4 class="text-success"><i class='fa fa-check-circle text-success mr-3'></i><span>Best Answer</span></h4></div><div class='bg-transparent mb-3'><h1>Input stream</h1><p>It is not clear if your 1000 events/second represent peaks or if it&#39;s a continuous load:</p><ul><li>if it&#39;s a peak, you could use a message queue as buffer to spread the load on the DB server over a longer time;</li><li>if it&#39;s constant load, the message queue alone is not sufficient, because the DB server will never be able to catch up.  Then you&#39;d need to think about a distributed database.</li></ul><h1>Proposed solution</h1><p>Intuitively,  in both cases, I&#39;d go for a <strong><a href="https://www.heroku.com/kafka" rel="noreferrer">Kafka</a></strong> based event-stream:</p><ul><li>All events are systematically published on a <a href="https://kafka.apache.org/intro" rel="noreferrer"><em><strong>kafka topic</strong></em></a></li><li>A consumer would subscribe to the events and store them to the database.</li><li>A query processor will handle the requests from the clients and query the DB.</li></ul><p>This is highly scalable at all levels:</p><ul><li>If DB server is the bottleneck, just add several consumers.  Each could subscribe to the topic, and write to a different DB server.  However, if the distribution occurs randomly across the DB servers, the query processor will not be able to predict the DB server to take and have to query several DB servers.  This could lead to a new bottleneck on the query side.</li><li>The DB distribution scheme could therefore be anticipated by organising the event stream into several topics (for example, using groups of keys or properties, to partition the DB according to a predictable logic).</li><li>If one message server is not sufficient to handle a growing flood of input events, you could add <em><strong>kafka partitions</strong></em> to distribute kafka topics across several physical servers.</li></ul><h1>Offering events not yet written in the DB to clients</h1><p>You want your clients to be able to get access also to information still in the pipe and not yet written to the DB.  This is a little more delicate.</p><h3>Option 1: Using a cache to complement db queries</h3><p>I have not analysed in depth, but the first idea that comes to my mind would be to make the query processor(s) a consumer(s) of the kafka topics, but in a different <a href="https://www.opsclarity.com/understanding-kafka-consumer-lag/" rel="noreferrer"><em><strong>kafka consumer group</strong></em></a>.  The request processor would then receive all the messages that the DB writer will receive, but independently. It could then keep them in a local cache.   The queries would then run on DB + cache (+ elimination of duplicates).</p><p>The design would then look like:</p><p><a href="https://i.stack.imgur.com/CLBOU.jpg" rel="noreferrer"><img src="https://i.stack.imgur.com/CLBOU.jpg" alt="enter image description here"/></a></p><p>The scalability of this query layer could be achieved by adding more query processors (each in its own consumer group).</p><h3>Option 2: design a dual API</h3><p>A better approach IMHO would be to offer a dual API (use the mechanism of the separate consumer group):</p><ul><li>a query API for accessing events in the DB and/or making analytics</li><li>a streaming API that just forwards messages directly from the topic</li></ul><p>The advantage, is that you let the client decide what is interesting.  This could avoid that you systematically merge DB data with freshly cashed data, when the client is only interested in new incoming events.  If the delicate merge between fresh and archived events is really needed, then the client would have to organise it.</p><h1>Variants</h1><p>I proposed kafka because it&#39;s designed for <a href="https://content.pivotal.io/blog/understanding-when-to-use-rabbitmq-or-apache-kafka" rel="noreferrer">very high volumes</a> with persistent messages so that you can restart the servers if needed.</p><p>You could build a similar architecture with RabbitMQ. However if you need persistent queues, <a href="https://www.rabbitmq.com/persistence-conf.html" rel="noreferrer">it might decrease performance</a>. Also, as far as I know, the only way to achieve the parallel consumption of the same messages by several readers (e.g. writer+cache) with RabbitMQ is to <a href="https://stackoverflow.com/a/41164627/3723423">clone the queues</a>. So a higher scalability might come at a higher price.</p></div></div><div class="col-4"></div></div></div></div><div class="col-12 col-md-4"> <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1731162805004860"
 data-ad-slot="1340983829"
 data-ad-format="auto"
 data-full-width-responsive="true"></ins>   <div class='mt-3 ml-4 border-bottom border-success'><h6><span>Related Question</span></h6></div><ul class='list-group list-group-flush'><li class="list-group-item"><a href='https://free-tor-game.com/software/architecture-for-multi-tenant-application/'>Architecture for multi-tenant application</a></li><li class="list-group-item"><a href='https://free-tor-game.com/software/event-sourcing-and-sync-between-write-and-read-model/'>Event sourcing and sync between write and read model</a></li></ul></div></div><footer class="entry-footer"></footer></article></div></div></div></main></div></div><footer id="colophon" class="site-footer"><div class="site-info"></div></footer></div>    <script type='text/javascript' src='http://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js?ver=5.6' id='mathjax-js'></script> <script type='text/javascript' src='https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/esm/popper.min.js?ver=1.14.7' id='popper-js'></script> <script type='text/javascript' src='https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/js/bootstrap.min.js?ver=4.3.1' id='bootstrap4-js'></script> <script type='text/javascript' id='itectec-common-js-extra'>var globalObject = {"homeUrl":"https:\/\/free-tor-game.com\/"};</script> <script defer src="https://free-tor-game.com/wp-content/cache/autoptimize/4/js/autoptimize_63b39f43631847816e6b0e70ea726624.js"></script></body></html>